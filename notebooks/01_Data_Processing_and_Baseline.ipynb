{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5c5e6a",
   "metadata": {},
   "source": [
    "1. Inicialización e importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c26898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las features se cargarán desde CSV.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# FIX para el ModuleNotFoundError\n",
    "if 'notebooks' in os.getcwd():\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "else:\n",
    "    sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Creamos las carpetas de resultados, ya que las figuras se guardarán aquí\n",
    "os.makedirs('results/figures', exist_ok=True)\n",
    "\n",
    "print(\"Las features se cargarán desde CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9f6b8",
   "metadata": {},
   "source": [
    "2. Cargar y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f441090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features cargadas exitosamente. Total de artículos: 240\n",
      "\n",
      "Muestra de Features Listas para el Modelo\n",
      "                                          X_baseline  \\\n",
      "0  trump insulted millions lost everything bushs ...   \n",
      "1  famous dog killed spot waited year owner retur...   \n",
      "\n",
      "                                         X_ocr_model  \n",
      "0  trump insulted millions lost everything bushs ...  \n",
      "1  famous dog killed spot waited year owner retur...  \n"
     ]
    }
   ],
   "source": [
    "PROCESSED_FILE = 'data/processed/fakenewsnet_processed.csv'\n",
    "\n",
    "try:\n",
    "    # Cargamos el archivo que generamos en la terminal con Scraping y OCR\n",
    "    df = pd.read_csv(PROCESSED_FILE)\n",
    "    print(f\"Features cargadas exitosamente. Total de artículos: {len(df)}\")\n",
    "    \n",
    "    # 1. Definir nuestras variables X e y\n",
    "    X = df[['X_baseline', 'X_ocr_model']]\n",
    "    y = df['label']\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo procesado en '{PROCESSED_FILE}'.\")\n",
    "    print(\"Por favor, asegúrese de haber ejecutado 'python src/data_loader.py' en la terminal.\")\n",
    "    X = None\n",
    "    y = None\n",
    "\n",
    "if X is not None:\n",
    "    print(\"\\nMuestra de Features Listas para el Modelo\")\n",
    "    print(X.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041912fd",
   "metadata": {},
   "source": [
    "3. Dividir los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ee22f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: 192\n",
      "Datos de prueba: 48\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos (80% entrenamiento, 20% prueba)\n",
    "if X is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, # Pasamos ambas columnas\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    print(f\"Datos de entrenamiento: {len(X_train)}\")\n",
    "    print(f\"Datos de prueba: {len(X_test)}\")\n",
    "else:\n",
    "    print(\"No se puede ejecutar la división de datos (X es nulo).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19167c7c",
   "metadata": {},
   "source": [
    "4. Experimento A: Modelo baseline solo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "\n",
    "    # 1. Vectorizador\n",
    "    vectorizer_base = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "    # 2. Vectorizar la feature X_baseline \n",
    "    X_train_vec_base = vectorizer_base.fit_transform(X_train['X_baseline'])\n",
    "    X_test_vec_base = vectorizer_base.transform(X_test['X_baseline'])\n",
    "\n",
    "    # 3. Modelo y Entrenamiento\n",
    "    model_base = RandomForestClassifier(random_state=42)\n",
    "    model_base.fit(X_train_vec_base, y_train)\n",
    "\n",
    "    # 4. Evaluación\n",
    "    print(\"\\nRESULTADOS:\")\n",
    "    y_pred_base = model_base.predict(X_test_vec_base)\n",
    "    print(classification_report(y_test, y_pred_base, target_names=['REAL (0)', 'FAKE (1)']))\n",
    "\n",
    "    # 5. Matriz de Confusión\n",
    "    ConfusionMatrixDisplay.from_estimator(model_base, X_test_vec_base, y_test, display_labels=['REAL', 'FAKE'])\n",
    "    plt.title('Matriz de Confusión - Baseline')\n",
    "    plt.savefig('results/figures/confusion_matrix_baseline.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f99cb0",
   "metadata": {},
   "source": [
    "5. Experimento B: Texto + OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "\n",
    "    # 1. Vectorizador\n",
    "    vectorizer_ocr = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "    # 2. Vectorizar la feature X_ocr_model \n",
    "    X_train_vec_ocr = vectorizer_ocr.fit_transform(X_train['X_ocr_model'])\n",
    "    X_test_vec_ocr = vectorizer_ocr.transform(X_test['X_ocr_model'])\n",
    "\n",
    "    # 3. Modelo y Entrenamiento\n",
    "    model_ocr = RandomForestClassifier(random_state=42)\n",
    "    model_ocr.fit(X_train_vec_ocr, y_train)\n",
    "\n",
    "    # 4. Evaluación\n",
    "    print(\"\\n--- RESULTADOS: MODELO PROPUESTO (Texto + OCR) ---\")\n",
    "    y_pred_ocr = model_ocr.predict(X_test_vec_ocr)\n",
    "    print(classification_report(y_test, y_pred_ocr, target_names=['REAL (0)', 'FAKE (1)']))\n",
    "\n",
    "    # 5. Matriz de Confusión\n",
    "    ConfusionMatrixDisplay.from_estimator(model_ocr, X_test_vec_ocr, y_test, display_labels=['REAL', 'FAKE'])\n",
    "    plt.title('Matriz de Confusión - Propuesto (Texto + OCR)')\n",
    "    plt.savefig('results/figures/confusion_matrix_ocr.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41163d",
   "metadata": {},
   "source": [
    "6. Setup and execution of Baseline TfidfVectorizer and RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26691eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar rutas\n",
    "processed_file = 'data/processed/fakenewsnet_processed.csv'\n",
    "results_dir = 'results/figures'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Cargar datos procesados\n",
    "df = pd.read_csv(processed_file)\n",
    "\n",
    "# Definir features y labels\n",
    "X = df['X_baseline']\n",
    "y = df['label']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Vectorización TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenamiento del modelo Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = rf_clf.predict(X_test_vec)\n",
    "\n",
    "# Reporte de clasificación\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Reporte de clasificación Baseline:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardar matriz de confusión\n",
    "disp = ConfusionMatrixDisplay.from_estimator(rf_clf, X_test_vec, y_test, cmap=plt.cm.Blues)\n",
    "plt.title(\"Baseline Random Forest - Matriz de Confusión\")\n",
    "plt.savefig(os.path.join(results_dir, 'baseline_confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Guardar métricas en CSV\n",
    "pd.DataFrame(report).transpose().to_csv('results/baseline_metrics.csv', index=True)\n",
    "print(\"Métricas y matriz de confusión guardadas para el modelo baseline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ae221",
   "metadata": {},
   "source": [
    "7. Execute multimodal experiment and save final results and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar rutas\n",
    "processed_file = 'data/processed/fakenewsnet_processed.csv'\n",
    "results_dir = 'results/figures'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Cargar datos procesados\n",
    "df = pd.read_csv(processed_file)\n",
    "\n",
    "# Definir features y labels\n",
    "X = df['X_ocr_model']  # Texto combinado + OCR\n",
    "y = df['label']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Vectorización TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenamiento del modelo Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = rf_clf.predict(X_test_vec)\n",
    "\n",
    "# Reporte de clasificación\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Reporte de clasificación Multimodal OCR:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardar matriz de confusión\n",
    "disp = ConfusionMatrixDisplay.from_estimator(rf_clf, X_test_vec, y_test, cmap=plt.cm.Blues)\n",
    "plt.title(\"OCR Random Forest - Matriz de Confusión\")\n",
    "plt.savefig(os.path.join(results_dir, 'ocr_confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Guardar métricas en CSV\n",
    "pd.DataFrame(report).transpose().to_csv('results/ocr_metrics.csv', index=True)\n",
    "print(\"Métricas y matriz de confusión guardadas para el modelo multimodal (OCR).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
